{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "045fb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import random\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "\n",
    "# from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from util import onehot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a82e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def transform(x):\n",
    "    return np.asarray(x) / 255\n",
    "\n",
    "\n",
    "MNIST_train = datasets.MNIST(root='./data', train = True , download=True, target_transform = onehot, transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "MNIST_test = datasets.MNIST(root='./data', train = False ,download=True,target_transform = onehot, transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed2c06dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(MNIST_train, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4d2ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.utils.data.DataLoader(train_set, batch_size=64,shuffle=True, num_workers=2)\n",
    "\n",
    "val_data = torch.utils.data.DataLoader(val_set, batch_size=64,shuffle=True, num_workers=2)\n",
    "\n",
    "test = torch.utils.data.DataLoader(test_data, batch_size=64,shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cf28571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length 60000\n",
      "Train Dataset Length 50000\n",
      "Validation Dataset Length 10000\n",
      "Test Dataset Length 10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Length\",len(MNIST_train))\n",
    "print(\"Train Dataset Length\",len(train_set))\n",
    "print(\"Validation Dataset Length\",len(val_set))\n",
    "print(\"Test Dataset Length\",len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68f7b024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, vector):\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2a86725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5e0ca31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_data))[0][0,0,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de64488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
